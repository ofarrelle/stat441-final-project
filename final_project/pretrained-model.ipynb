{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-11T05:02:07.974254Z","iopub.execute_input":"2021-12-11T05:02:07.974516Z","iopub.status.idle":"2021-12-11T05:02:07.979448Z","shell.execute_reply.started":"2021-12-11T05:02:07.974489Z","shell.execute_reply":"2021-12-11T05:02:07.978415Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import models, Input, layers, optimizers, regularizers, callbacks, losses, metrics \nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold, train_test_split\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:02:08.171576Z","iopub.execute_input":"2021-12-11T05:02:08.171877Z","iopub.status.idle":"2021-12-11T05:02:14.981830Z","shell.execute_reply.started":"2021-12-11T05:02:08.171842Z","shell.execute_reply":"2021-12-11T05:02:14.980747Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# FOR KAGGLE\ntrain_images_dir = '../input/petfinder-pawpularity-score/train/'\ntest_images_dir = '../input/petfinder-pawpularity-score/test/'\n\n# FOR LOCAL PC\n# train_images_dir = './dataset/train/'\n# test_images_dir = './dataset/test/'","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:02:14.983582Z","iopub.execute_input":"2021-12-11T05:02:14.983814Z","iopub.status.idle":"2021-12-11T05:02:14.987942Z","shell.execute_reply.started":"2021-12-11T05:02:14.983788Z","shell.execute_reply":"2021-12-11T05:02:14.987232Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntrain_df.loc[:, 'filename'] = train_images_dir + train_df['Id'] + '.jpg'\n\ntest_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest_df.loc[:, 'filename'] = test_images_dir + test_df['Id'] + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:02:14.989249Z","iopub.execute_input":"2021-12-11T05:02:14.989850Z","iopub.status.idle":"2021-12-11T05:02:15.067125Z","shell.execute_reply.started":"2021-12-11T05:02:14.989817Z","shell.execute_reply":"2021-12-11T05:02:15.066161Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_df.loc[:, train_df.columns != 'Pawpularity'], train_df['Pawpularity'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:02:15.068919Z","iopub.execute_input":"2021-12-11T05:02:15.069223Z","iopub.status.idle":"2021-12-11T05:02:15.086681Z","shell.execute_reply.started":"2021-12-11T05:02:15.069192Z","shell.execute_reply":"2021-12-11T05:02:15.085950Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:02:15.088175Z","iopub.execute_input":"2021-12-11T05:02:15.088397Z","iopub.status.idle":"2021-12-11T05:02:15.094661Z","shell.execute_reply.started":"2021-12-11T05:02:15.088371Z","shell.execute_reply":"2021-12-11T05:02:15.093914Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"img_size = (128, 128, 3)\nBATCH_SIZE = 32\n\ndef parse_image(inputs, label=None):\n    image_string = tf.io.read_file(inputs[0])\n    image = tf.image.decode_jpeg(image_string, channels=img_size[2])\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, img_size[:2])\n    return (image, inputs[1]), label\n\ndef get_dataset(inputs, label=None, shuffle=False):    \n    dataset = tf.data.TFRecordDataset.from_tensor_slices((inputs, label))     \n    if shuffle:\n        dataset = dataset.shuffle(np.size(inputs[0], 0))\n    dataset = dataset.map(parse_image, num_parallel_calls=4)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(True)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:02:15.095883Z","iopub.execute_input":"2021-12-11T05:02:15.096495Z","iopub.status.idle":"2021-12-11T05:02:15.107413Z","shell.execute_reply.started":"2021-12-11T05:02:15.096451Z","shell.execute_reply":"2021-12-11T05:02:15.106593Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_dataset((X_train['filename'], X_train[cols]), y_train, shuffle=True)\nval_dataset = get_dataset((X_val['filename'], X_val[cols]), y_val, shuffle=True)\ntest_dataset = get_dataset((test_df['filename'], test_df[cols]))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:02:15.108985Z","iopub.execute_input":"2021-12-11T05:02:15.109289Z","iopub.status.idle":"2021-12-11T05:02:15.335109Z","shell.execute_reply.started":"2021-12-11T05:02:15.109252Z","shell.execute_reply":"2021-12-11T05:02:15.334118Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"img_augmentation = tf.keras.models.Sequential(\n    [\n        layers.RandomRotation(factor=1/32),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomFlip('horizontal'),\n        layers.RandomContrast(factor=0.1),\n    ],\n    name=\"img_augmentation\",\n)\n\ndef build_model():\n    # inputs\n    image_input = Input(shape=img_size)\n    tabular_input = Input(shape=(len(cols),))\n    \n    x = img_augmentation(image_input)\n    mobilenet = tf.keras.applications.MobileNetV3Small(include_top=False, weights=\"imagenet\")\n    # Freeze the pretrained weights\n    mobilenet.trainable = False\n    # Rebuild top\n    x = mobilenet(x)\n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n    x = layers.BatchNormalization()(x)\n    top_dropout_rate = 0.2\n    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n    flat_img = layers.Dense(64, activation=\"relu\", name=\"features\")(x)\n\n    # tabular metadata processing\n    y = layers.Dense(128, activation='relu')(tabular_input)\n    y = layers.Dropout(0.3)(y)\n    y = layers.Dense(64, activation='relu')(y)\n    y = layers.Dropout(0.3)(y)\n\n    # combining\n    z = layers.Concatenate(name='concat')([flat_img, y])\n    z = layers.Dense(32, activation='relu')(z)\n    z = layers.Dropout(0.3)(z)\n    z = layers.Dense(16, activation='relu')(z)\n    output = layers.Dense(1)(z)\n    # output = layers.Rescaling(100)(z)\n\n    model = tf.keras.Model(\n        inputs = (image_input, tabular_input),\n        outputs=output\n    )\n    model.compile(optimizer=optimizers.Adam(), \n                  loss=losses.MeanSquaredError(), \n                  metrics=[metrics.RootMeanSquaredError()]\n                 )\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:03:22.762140Z","iopub.execute_input":"2021-12-11T05:03:22.762395Z","iopub.status.idle":"2021-12-11T05:03:22.788521Z","shell.execute_reply.started":"2021-12-11T05:03:22.762368Z","shell.execute_reply":"2021-12-11T05:03:22.787777Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = callbacks.EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.002, patience=10)\nreduce_lr = callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n                              patience=5, min_lr=0.000001)\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=64,\n#     steps_per_epoch=20,\n#     use_multiprocessing=True,\n#     callbacks=[es, reduce_lr]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T05:03:22.955380Z","iopub.execute_input":"2021-12-11T05:03:22.955671Z","iopub.status.idle":"2021-12-11T05:05:35.847120Z","shell.execute_reply.started":"2021-12-11T05:03:22.955643Z","shell.execute_reply":"2021-12-11T05:05:35.846255Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['root_mean_squared_error'])\nplt.plot(history.history['val_root_mean_squared_error'])\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T02:43:58.575451Z","iopub.execute_input":"2021-12-11T02:43:58.576044Z","iopub.status.idle":"2021-12-11T02:44:03.771891Z","shell.execute_reply.started":"2021-12-11T02:43:58.576008Z","shell.execute_reply":"2021-12-11T02:44:03.771243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submisson_df = test_df[['Id']]\nsubmisson_df['Pawpularity'] = preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submisson_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submisson_df.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}