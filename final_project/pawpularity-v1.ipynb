{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-11T04:22:12.357386Z","iopub.execute_input":"2021-12-11T04:22:12.357642Z","iopub.status.idle":"2021-12-11T04:22:12.363159Z","shell.execute_reply.started":"2021-12-11T04:22:12.357608Z","shell.execute_reply":"2021-12-11T04:22:12.362387Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import models, Input, layers, optimizers, regularizers, callbacks, losses, metrics \nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold, train_test_split\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:12.364642Z","iopub.execute_input":"2021-12-11T04:22:12.364891Z","iopub.status.idle":"2021-12-11T04:22:12.374987Z","shell.execute_reply.started":"2021-12-11T04:22:12.364859Z","shell.execute_reply":"2021-12-11T04:22:12.374278Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# FOR KAGGLE\ntrain_images_dir = '../input/petfinder-pawpularity-score/train/'\ntest_images_dir = '../input/petfinder-pawpularity-score/test/'\n\n# FOR LOCAL PC\n# train_images_dir = './dataset/train/'\n# test_images_dir = './dataset/test/'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntrain_df.loc[:, 'filename'] = train_images_dir + train_df['Id'] + '.jpg'\n\ntest_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest_df.loc[:, 'filename'] = test_images_dir + test_df['Id'] + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:12.377964Z","iopub.execute_input":"2021-12-11T04:22:12.378162Z","iopub.status.idle":"2021-12-11T04:22:12.409491Z","shell.execute_reply.started":"2021-12-11T04:22:12.378134Z","shell.execute_reply":"2021-12-11T04:22:12.408829Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:37:37.173073Z","iopub.execute_input":"2021-12-11T04:37:37.173687Z","iopub.status.idle":"2021-12-11T04:37:37.193280Z","shell.execute_reply.started":"2021-12-11T04:37:37.173642Z","shell.execute_reply":"2021-12-11T04:37:37.192607Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_df.loc[:, train_df.columns != 'Pawpularity'], train_df['Pawpularity'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:12.430876Z","iopub.execute_input":"2021-12-11T04:22:12.431267Z","iopub.status.idle":"2021-12-11T04:22:12.442180Z","shell.execute_reply.started":"2021-12-11T04:22:12.431228Z","shell.execute_reply":"2021-12-11T04:22:12.441561Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:12.445101Z","iopub.execute_input":"2021-12-11T04:22:12.445348Z","iopub.status.idle":"2021-12-11T04:22:12.448832Z","shell.execute_reply.started":"2021-12-11T04:22:12.445322Z","shell.execute_reply":"2021-12-11T04:22:12.448096Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"img_size = (128, 128, 3)\nBATCH_SIZE = 32\n\ndef parse_image(inputs, label=None):\n    image_string = tf.io.read_file(inputs[0])\n    image = tf.image.decode_jpeg(image_string, channels=img_size[2])\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, img_size[:2])\n    return (image, inputs[1]), label\n\ndef get_dataset(inputs, label=None, shuffle=False):    \n    dataset = tf.data.TFRecordDataset.from_tensor_slices((inputs, label))     \n    if shuffle:\n        dataset = dataset.shuffle(np.size(inputs[0], 0))\n    dataset = dataset.map(parse_image, num_parallel_calls=4)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(True)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:12.450190Z","iopub.execute_input":"2021-12-11T04:22:12.450627Z","iopub.status.idle":"2021-12-11T04:22:12.459880Z","shell.execute_reply.started":"2021-12-11T04:22:12.450591Z","shell.execute_reply":"2021-12-11T04:22:12.459220Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_dataset((X_train['filename'], X_train[cols]), y_train, shuffle=True)\nval_dataset = get_dataset((X_val['filename'], X_val[cols]), y_val, shuffle=True)\ntest_dataset = get_dataset((test_df['filename'], test_df[cols]))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:12.461240Z","iopub.execute_input":"2021-12-11T04:22:12.461504Z","iopub.status.idle":"2021-12-11T04:22:12.522069Z","shell.execute_reply.started":"2021-12-11T04:22:12.461472Z","shell.execute_reply":"2021-12-11T04:22:12.521469Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# inputs\nimage_input = Input(shape=img_size)\ntabular_input = Input(shape=(len(cols),))\n\n# image processing\nx = layers.Conv2D(16, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu')(image_input)\nx = layers.BatchNormalization()(x)\nx = layers.MaxPooling2D(2, 2)(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu')(image_input)\nx = layers.BatchNormalization()(x)\nx = layers.MaxPooling2D(2, 2)(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu')(x)\nx = layers.BatchNormalization()(x)\nx = layers.MaxPooling2D(2, 2)(x)\nx = layers.Dropout(0.2)(x)\nflat_img = layers.Flatten()(x)\n\n# tabular metadata processing\ny = layers.Dense(128, activation='relu')(tabular_input)\ny = layers.Dropout(0.3)(y)\ny = layers.Dense(64, activation='relu')(y)\ny = layers.Dropout(0.3)(y)\n\n# combining\nz = layers.Concatenate(name='concat')([flat_img, y])\nz = layers.Dense(32, activation='relu')(z)\nz = layers.Dropout(0.3)(z)\nz = layers.Dense(16, activation='relu')(z)\noutput = layers.Dense(1)(z)\n# output = layers.Rescaling(100)(z)\n\nmodel = tf.keras.Model(\n    inputs = (image_input, tabular_input),\n    outputs=output\n)\nmodel.compile(optimizer=optimizers.Adam(), \n              loss=losses.MeanSquaredError(), \n              metrics=[metrics.RootMeanSquaredError()]\n             )","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:29.563779Z","iopub.execute_input":"2021-12-11T04:22:29.564038Z","iopub.status.idle":"2021-12-11T04:22:29.696519Z","shell.execute_reply.started":"2021-12-11T04:22:29.564008Z","shell.execute_reply":"2021-12-11T04:22:29.695733Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"es = callbacks.EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.002, patience=10)\nreduce_lr = callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n                              patience=5, min_lr=0.000001)\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=128,\n#     steps_per_epoch=20,\n#     use_multiprocessing=True,\n#     callbacks=[es, reduce_lr]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:22:31.347097Z","iopub.execute_input":"2021-12-11T04:22:31.347363Z","iopub.status.idle":"2021-12-11T04:25:54.139508Z","shell.execute_reply.started":"2021-12-11T04:22:31.347332Z","shell.execute_reply":"2021-12-11T04:25:54.138724Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['root_mean_squared_error'])\nplt.plot(history.history['val_root_mean_squared_error'])\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:25:54.143399Z","iopub.execute_input":"2021-12-11T04:25:54.143621Z","iopub.status.idle":"2021-12-11T04:25:54.353897Z","shell.execute_reply.started":"2021-12-11T04:25:54.143595Z","shell.execute_reply":"2021-12-11T04:25:54.353230Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:25:54.355137Z","iopub.execute_input":"2021-12-11T04:25:54.355551Z","iopub.status.idle":"2021-12-11T04:25:54.536745Z","shell.execute_reply.started":"2021-12-11T04:25:54.355502Z","shell.execute_reply":"2021-12-11T04:25:54.536099Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:25:54.538736Z","iopub.execute_input":"2021-12-11T04:25:54.539006Z","iopub.status.idle":"2021-12-11T04:25:54.729528Z","shell.execute_reply.started":"2021-12-11T04:25:54.538969Z","shell.execute_reply":"2021-12-11T04:25:54.728752Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"submisson_df = test_df[['Id']]\nsubmisson_df['Pawpularity'] = preds","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:25:54.731197Z","iopub.execute_input":"2021-12-11T04:25:54.731477Z","iopub.status.idle":"2021-12-11T04:25:54.738287Z","shell.execute_reply.started":"2021-12-11T04:25:54.731437Z","shell.execute_reply":"2021-12-11T04:25:54.736975Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"submisson_df","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:31:17.658056Z","iopub.execute_input":"2021-12-11T04:31:17.658319Z","iopub.status.idle":"2021-12-11T04:31:17.667746Z","shell.execute_reply.started":"2021-12-11T04:31:17.658291Z","shell.execute_reply":"2021-12-11T04:31:17.666935Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"submisson_df.to_csv('submission.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T04:21:37.713510Z","iopub.status.idle":"2021-12-11T04:21:37.714047Z","shell.execute_reply.started":"2021-12-11T04:21:37.713813Z","shell.execute_reply":"2021-12-11T04:21:37.713840Z"},"trusted":true},"execution_count":null,"outputs":[]}]}