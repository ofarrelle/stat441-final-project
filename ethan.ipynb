{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import PIL\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject Focus  Eyes  Face  Near  Action  Accessory  Group  Collage  Human  \\\n",
       "0              0     1     1     1       0          0      1        0      0   \n",
       "1              0     1     1     0       0          0      0        0      0   \n",
       "\n",
       "   Occlusion  Info  Blur  \n",
       "0          0     0     0  \n",
       "1          0     0     0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./dataset/train.csv')\n",
    "train_df['Id'] = './dataset/train/' + train_df['Id'] + '.jpg'\n",
    "img_names = train_df.pop('Id').to_numpy()\n",
    "targets = train_df.pop('Pawpularity').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 200\n",
    "batch_size = 32\n",
    "\n",
    "def parse_image_file(inputs, label):\n",
    "    image = tf.io.read_file(inputs[0])\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [image_size, image_size])\n",
    "    return ( (image, inputs[1]), label)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(( (img_names, train_df.to_numpy(dtype='int8')), targets ))\n",
    "train_dataset = train_dataset.map(parse_image_file).shuffle(100).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cb1_conv (Conv2D)               (None, 200, 200, 32) 896         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cb1_pool (MaxPooling2D)         (None, 100, 100, 32) 0           cb1_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cb1_drop (Dropout)              (None, 100, 100, 32) 0           cb1_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cb2_conv (Conv2D)               (None, 100, 100, 64) 18496       cb1_drop[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cb2_pool (MaxPooling2D)         (None, 50, 50, 64)   0           cb2_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cb2_drop (Dropout)              (None, 50, 50, 64)   0           cb2_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tabular (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flat (Flatten)                  (None, 160000)       0           cb2_drop[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "processed_tabular (Dense)       (None, 32)           416         tabular[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 160032)       0           flat[0][0]                       \n",
      "                                                                 processed_tabular[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 160032)       0           concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           10242112    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           1040        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            17          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,262,977\n",
      "Trainable params: 10,262,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# functional API\n",
    "\n",
    "# inputs\n",
    "image_input = tf.keras.Input(shape=(image_size, image_size, 3), name='image')\n",
    "tabular_input = tf.keras.Input(shape=(train_df.shape[1],), name='tabular')\n",
    "\n",
    "# image processing\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', name='cb1_conv')(image_input)\n",
    "x = tf.keras.layers.MaxPooling2D(2, 2, name='cb1_pool')(x)\n",
    "x = tf.keras.layers.Dropout(0.2, name='cb1_drop')(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', name='cb2_conv')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2, 2, name='cb2_pool')(x)\n",
    "x = tf.keras.layers.Dropout(0.2, name='cb2_drop')(x)\n",
    "\n",
    "flat_img = tf.keras.layers.Flatten(name='flat')(x)\n",
    "\n",
    "# tabular metadata processing\n",
    "processed_tabular = tf.keras.layers.Dense(32, activation='relu', name='processed_tabular')(tabular_input)\n",
    "\n",
    "# combining\n",
    "y = tf.keras.layers.Concatenate(name='concat')([flat_img, processed_tabular])\n",
    "y = tf.keras.layers.Dropout(0.3)(y)\n",
    "y = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "y = tf.keras.layers.Dropout(0.3)(y)\n",
    "y = tf.keras.layers.Dense(16, activation='relu')(y)\n",
    "y = tf.keras.layers.Dense(1)(y)\n",
    "output = tf.keras.layers.Rescaling(100)(y)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs = [image_input, tabular_input],\n",
    "    outputs=output\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "310/310 [==============================] - 390s 1s/step - loss: 540.0953\n",
      "Epoch 2/2\n",
      "310/310 [==============================] - 415s 1s/step - loss: 438.3320\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'mean_squared_error'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
